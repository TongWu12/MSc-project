{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e599f8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import scipy.io\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from data_handling import CppDataExtraction,EigenData,XyDataFormat,MlModelDataFormat,PlotType,MlPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d8f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EigenData(object):\n",
    "    '''Represents the original experiment data.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self._eigenworms = None\n",
    "\n",
    "    def get_eigenworms(self, eigen_path):\n",
    "        '''\n",
    "        Loads the matlab files from the original experiment and parses them\n",
    "        into expected numpy formats.\n",
    "\n",
    "        Eigenworms are stored as 100 'angles' at equidistributed coordinates down the body.\n",
    "        \n",
    "        The original format of the Stephens data eigenmodes.\n",
    "        '''\n",
    "        # Load the matlab files into numpy arrays\n",
    "        # 100*100\n",
    "        eigenworms = scipy.io.loadmat(eigen_path)\n",
    "        self._eigenworms = eigenworms[\"EigenWorms\"].transpose()\n",
    "        return self._eigenworms\n",
    "\n",
    "    def get_footage(self, footage_path):\n",
    "        '''\n",
    "        Loads the matlab files from the original experiment and parses them\n",
    "        into expected numpy formats.\n",
    "\n",
    "        Footage is stored as coefficients with respect to the eigenworm basis.\n",
    "        \n",
    "        Format is a cell array of 12 cells, each containing an Nx5 matrix, where a row is a time point, and each eigenmode has a column.\n",
    "        \n",
    "        experiment coefficient values\n",
    "        \n",
    "        The original format of the Stephens data eigenvalues\n",
    "        '''\n",
    "        # 12 * 5 *33600\n",
    "        f = h5py.File(footage_path, 'r')\n",
    "        footage = {}\n",
    "        for k, v in f.items():\n",
    "            if k != 'tr':\n",
    "                for k2, v2 in v.items():\n",
    "                    if v2.shape == (5, 33600) or v2.shape == (6, 33600):\n",
    "                        footage[k2] = np.array(v2)\n",
    "        return footage\n",
    "\n",
    "    def reconstruct(self, coefficients):\n",
    "        '''\n",
    "        Reconstruct multiple postures from basis coefficients to angles.\n",
    "        '''\n",
    "        n_basis_required =  coefficients.shape[0]\n",
    "        print(self._eigenworms[0:n_basis_required, :].transpose().shape,coefficients.shape)\n",
    "        return self._eigenworms[0:n_basis_required, :].transpose() @ coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6fe4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8679128990624087799\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "109d9643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "c (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "d (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "e (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "f (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "g (6, 33600)\n",
      "(100, 6) (6, 33600)\n",
      "--> (100, 33600)\n",
      "h (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "i (6, 33600)\n",
      "(100, 6) (6, 33600)\n",
      "--> (100, 33600)\n",
      "j (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "k (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "l (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n",
      "m (5, 33600)\n",
      "(100, 5) (5, 33600)\n",
      "--> (100, 33600)\n"
     ]
    }
   ],
   "source": [
    "data = EigenData()\n",
    "eigenworms=data.get_eigenworms('EigenWorms.mat')\n",
    "footage = data.get_footage('20150814-All-PNAS2011-DataStitched .mat')\n",
    "\n",
    "first_5_eigenworms = eigenworms[0:5,:]\n",
    "eig_worm_0 = eigenworms[0,:]\n",
    "eig_worm_1 = eigenworms[1,:]\n",
    "eig_worm_2 = eigenworms[2,:]\n",
    "eig_worm_3 = eigenworms[3,:]\n",
    "eig_worm_4 = eigenworms[4,:]\n",
    "\n",
    "for k in footage.keys():\n",
    "    print(k, footage[k].shape)\n",
    "    r = data.reconstruct(footage[k])\n",
    "    print('-->', r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267cd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CppDataExtraction(object):\n",
    "\n",
    "    _nsre = re.compile('([0-9]+)')\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod    \n",
    "    def natural_sort_key(s):\n",
    "        return [int(text) if text.isdigit() else text.lower()\n",
    "                for text in re.split(CppDataExtraction._nsre, s)]   \n",
    "\n",
    "    @staticmethod\n",
    "    def get_list_of_files(path):\n",
    "        #TODO: Currently only setup for 1 job\n",
    "        # loop through all the files in the job\n",
    "        list_of_files = []\n",
    "        for subdir, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                list_of_files.append(file_path)\n",
    "        list_of_files.sort(key=CppDataExtraction.natural_sort_key)\n",
    "        return list_of_files\n",
    "\n",
    "    @staticmethod\n",
    "    def get_list_of_points(list_of_files):\n",
    "        list_of_data_points = []\n",
    "        for file in list_of_files:\n",
    "            f = open(file)\n",
    "            lines = f.readlines()\n",
    "            datapoints = np.array([x.split(',') for x in lines], dtype=np.float64)\n",
    "            list_of_data_points.append(datapoints)\n",
    "        return list_of_data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d105bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worm1', 'worm2', 'worm3', 'worm4', 'worm5', 'worm6', 'worm7', 'worm8', 'worm9', 'orm10', 'orm11']\n",
      "['eigvals1', 'eigvals2', 'eigvals3', 'eigvals4', 'eigvals5', 'eigvals6', 'eigvals7', 'eigvals8', 'eigvals9', 'igvals10', 'igvals11']\n",
      "[(29871, 5), (31844, 5), (31862, 5), (32980, 5), (33095, 5), (33166, 5), (31316, 5), (33538, 5), (33457, 5), (33313, 5), (28494, 5)]\n",
      "[(29871, 5), (31844, 5), (31862, 5), (32980, 5), (33095, 5), (33166, 5), (31316, 5), (33538, 5), (33457, 5), (33313, 5), (28494, 5)]\n"
     ]
    }
   ],
   "source": [
    " rootdir_curvatures = 'trained-data'\n",
    "list_of_curve_files = CppDataExtraction.get_list_of_files(rootdir_curvatures)\n",
    "print([file[-9:-4] for file in list_of_curve_files])\n",
    "#Load in the muscle curvatures\n",
    "rootdir_muscle = 'eigenworm-drive-data-cp'\n",
    "'''eigenworm-drive-data-cp\n",
    "Contains the original Stephens experiment coefficient values for each of the 12 worms.'''\n",
    "list_of_muscle_files = CppDataExtraction.get_list_of_files(rootdir_muscle)\n",
    "# Remove the TEST file\n",
    "list_of_muscle_files = list_of_muscle_files[:-1]\n",
    "# Remove the zeroth file (TODO: NOT CURRENTLY PROCESSED)\n",
    "list_of_muscle_files = list_of_muscle_files[1:]\n",
    "print([file[-12:-4] for file in list_of_muscle_files])\n",
    "list_of_curve_points = CppDataExtraction.get_list_of_points(list_of_curve_files)\n",
    "print(([curve.shape for curve in list_of_curve_points]))\n",
    "list_of_muscle_points = CppDataExtraction.get_list_of_points(list_of_muscle_files)\n",
    "print(([muscle.shape for muscle in list_of_muscle_points]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08b591e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curve point size: 29871 Muscle point size: 29871\n",
      "Curve point size: 31844 Muscle point size: 31844\n",
      "Curve point size: 31862 Muscle point size: 31862\n",
      "Curve point size: 32980 Muscle point size: 32980\n",
      "Curve point size: 33095 Muscle point size: 33095\n",
      "Curve point size: 33166 Muscle point size: 33166\n",
      "Curve point size: 31316 Muscle point size: 31316\n",
      "Curve point size: 33538 Muscle point size: 33538\n",
      "Curve point size: 33457 Muscle point size: 33457\n",
      "Curve point size: 33313 Muscle point size: 33313\n",
      "Curve point size: 28494 Muscle point size: 28494\n",
      "(352925, 5)\n",
      "(352925, 10)\n"
     ]
    }
   ],
   "source": [
    "DEBUG_LIMIT = None\n",
    "offset = 1\n",
    "xs = []\n",
    "ys = []\n",
    "for worm_idx in range(len(list_of_curve_files)):\n",
    "    if(worm_idx == worm_idx): \n",
    "        muscle_points = list_of_muscle_points[worm_idx]\n",
    "        curve_points = list_of_curve_points[worm_idx]\n",
    "        print(\"Curve point size: \" + str(len(curve_points)) + \" Muscle point size: \" + str(len(muscle_points)))\n",
    "\n",
    "        for idx in range(len(curve_points[:DEBUG_LIMIT])- offset):\n",
    "            y = muscle_points[idx+ int(offset/2)+1]\n",
    "            ys.append(y)\n",
    "            x = np.array([])\n",
    "            for off in range(offset+1):\n",
    "                x = np.concatenate((x, curve_points[idx+off]))\n",
    "            xs.append(x)\n",
    "\n",
    "ys = np.array(ys)[0:]\n",
    "xs = np.array(xs)[0:]\n",
    "print(ys.shape)\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcfa914e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352925, 10)\n",
      "(352925, 5)\n",
      "\n",
      "\n",
      "X Min: 0.0 X Max: 1.0\n",
      "Y Min: 0.0 Y Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalise\n",
    "xs_norm = np.nan_to_num((xs - xs.min(axis=0)) / (xs.max(axis=0)- xs.min(axis=0)))\n",
    "ys_norm = np.nan_to_num((ys - ys.min(axis=0)) / (ys.max(axis=0)- ys.min(axis=0)))\n",
    "\n",
    "print(xs_norm.shape)\n",
    "print(ys_norm.shape)\n",
    "print(\"\\n\")\n",
    "print(\"X Min: \" + str(np.amin(xs_norm)) + \" X Max: \" + str(np.amax(xs_norm)))\n",
    "print(\"Y Min: \" + str(np.amin(ys_norm)) + \" Y Max: \" + str(np.amax(ys_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a748569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Min: -13.6624 X Max: 13.4188\n",
      "Y Min: -24.908524 Y Max: 33.532132\n"
     ]
    }
   ],
   "source": [
    "print(\"X Min: \" + str(np.amin(xs)) + \" X Max: \" + str(np.amax(xs)))\n",
    "print(\"Y Min: \" + str(np.amin(ys)) + \" Y Max: \" + str(np.amax(ys)))\n",
    "original_y_min = np.amin(ys)\n",
    "original_y_max = np.amax(ys)\n",
    "original_x_min = np.amin(xs)\n",
    "original_x_max = np.amax(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2493debf",
   "metadata": {},
   "outputs": [],
   "source": [
    " # LOAD IN NEW DATA HERE\n",
    "def NEW_inner_extract_x_only_vector(list_of_curve_points, worm_idx,xs):\n",
    "    DEBUG_LIMIT = None\n",
    "    offset = 1\n",
    "    curve_points = list_of_curve_points[worm_idx]\n",
    "    for idx in range(len(curve_points[:DEBUG_LIMIT])- offset):\n",
    "        x = np.array([])\n",
    "        for off in range(offset+1):\n",
    "            x = np.concatenate((x, curve_points[idx+off]))\n",
    "        xs.append(x)\n",
    "    return np.array(xs)\n",
    "def NEW_inner_extract_xy_vector(list_of_muscle_points, list_of_curve_points, worm_idx, xs, ys):\n",
    "    DEBUG_LIMIT = None\n",
    "    offset = 1\n",
    "    muscle_points = list_of_muscle_points[worm_idx]\n",
    "    curve_points = list_of_curve_points[worm_idx]\n",
    "    print(\"Curve point size: \" + str(len(curve_points)) + \" Muscle point size: \" + str(len(muscle_points)))\n",
    "    \n",
    "    for idx in range(len(curve_points[:DEBUG_LIMIT])- offset):\n",
    "        y = muscle_points[idx+ int(offset/2)+1]\n",
    "        ys.append(y)\n",
    "        x = np.array([])\n",
    "        for off in range(offset+1):\n",
    "            x = np.concatenate((x, curve_points[idx+off]))\n",
    "        xs.append(x)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01d3babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_VALUE=\"e0p1\"\n",
    "new_x_data = np.loadtxt(open(\"kappa_unseen_data/kappa_unseen_data_\"+ E_VALUE + \".txt\", \"rb\"), delimiter=\",\")\n",
    "new_y_data = np.loadtxt(open(\"beta_unseen_data/eigvals0.txt\", \"rb\"), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0deeb433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curve point size: 33486 Muscle point size: 33486\n"
     ]
    }
   ],
   "source": [
    "#Create the list of files\n",
    "new_x_data_list = [new_x_data]\n",
    "new_y_data_list = [new_y_data]\n",
    "n_xs ,n_ys = NEW_inner_extract_xy_vector(new_y_data_list, new_x_data_list, 0, [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f081e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Unseen Generated Kappa) Xs Shape: (33485, 10),Xs Min: -14.0341, Xs Max: 13.2323\n",
      "(Unseen Fake Beta) Ys Shape: (33485, 5), Ys Min: -19.650889, Ys Max: 27.380742\n"
     ]
    }
   ],
   "source": [
    "print(\"(Unseen Generated Kappa) Xs Shape: \" + str(n_xs.shape) + \",Xs Min: \" + str(np.amin(n_xs)) + \", Xs Max: \" + str(np.amax(n_xs)))\n",
    "print(\"(Unseen Fake Beta) Ys Shape: \" + str(n_ys.shape) + \", Ys Min: \" + str(np.amin(n_ys)) + \", Ys Max: \" + str(np.amax(n_ys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80440e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_Xs Shape: (33485, 10), n_Xs Min: -0.013725388830627912, n_Xs Max: 0.9931133036940757\n",
      "n_Ys Shape: (33485, 5), n_Ys Min: 0.08996536589185448, n_Ys Max: 0.8947412568401012\n"
     ]
    }
   ],
   "source": [
    " # Normalise new data to within bounds\n",
    "# n_xs_norm = xs_norm\n",
    "# n_ys_norm = ys_norm\n",
    "n_xs_norm = np.nan_to_num((n_xs - original_x_min) / (original_x_max- original_x_min))\n",
    "n_ys_norm = np.nan_to_num((n_ys - original_y_min) / (original_y_max- original_y_min))\n",
    "# n_xs_norm = np.nan_to_num((n_xs - n_xs.min(axis=0)) / (n_xs.max(axis=0)- n_xs.min(axis=0)))\n",
    "# n_ys_norm = np.nan_to_num((n_ys - n_ys.min(axis=0)) / (n_ys.max(axis=0)- n_ys.min(axis=0)))\n",
    "print(\"n_Xs Shape: \" + str(n_xs_norm.shape) + \", n_Xs Min: \" + str(np.amin(n_xs_norm)) + \", n_Xs Max: \" + str(np.amax(n_xs_norm)))\n",
    "print(\"n_Ys Shape: \" + str(n_ys_norm.shape) + \", n_Ys Min: \" + str(np.amin(n_ys_norm)) + \", n_Ys Max: \" + str(np.amax(n_ys_norm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963d218",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate a quick random string (prevents file save bug)\n",
    "np.random.seed()\n",
    "rand_str = str(np.random.randint(1000))\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "timestep = 5\n",
    "# (nb_samples, timesteps, input_dim)\n",
    "xs_norm_rec, ys_norm_rec = MlModelDataFormat.convert_data_set_to_recurrence(n_xs_norm, n_ys_norm, timestep)\n",
    "print(xs_norm_rec.shape)\n",
    "print(ys_norm_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "rand_str = str(np.random.randint(1000))\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# Data shape\n",
    "num_train_samples = int(xs_norm.shape[0] * 0.8)\n",
    "\n",
    "timestep = 5\n",
    "\n",
    "def split_into_train_test(x, y, num_train_samples):\n",
    "    # Split into train/ test sets\n",
    "    num_test_samples = x.shape[0] - num_train_samples\n",
    "\n",
    "    print(\"Number Test Samples: \" + str(num_test_samples))\n",
    "    trainX = x[0:num_train_samples,:,:]\n",
    "    trainY = y[0:num_train_samples,:]\n",
    "\n",
    "    testX = x[num_train_samples:num_train_samples+num_test_samples,:,:]\n",
    "    testY = y[num_train_samples:num_train_samples+num_test_samples,:]\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "xs_norm_rec, ys_norm_rec = MlModelDataFormat.convert_data_set_to_recurrence(xs_norm, ys_norm, timestep)\n",
    "\n",
    "trainX, trainY, testX, testY = split_into_train_test(xs_norm_rec, ys_norm_rec, num_train_samples)\n",
    "\n",
    "# Check the output shapes\n",
    "print(\"Final shapes: train_x=\" + str(trainX.shape) + \", train_y=\" \n",
    "      + str(trainY.shape) + \", test_x=\" + str(testX.shape) + \", test_y=\" +str(testY.shape))\n",
    "print(ys_norm_rec[1290:1295])\n",
    "print(testY[90:95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6929b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.models.Sequential()\n",
    "model.add(k.layers.LSTM(20, input_shape=(timestep,10), return_sequences=True))\n",
    "model.add(k.layers.LSTM(5, input_shape=(timestep,10), return_sequences=False))\n",
    "model.add(k.layers.Dense(5))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[\"mape\"])\n",
    "history = model.fit(trainX, trainY, validation_split=0.2, epochs=100, batch_size=100, verbose=2)\n",
    "\n",
    "try:\n",
    "    model.save_weights('neural-1-unit-weights-v2-e10-base'+\n",
    "                       str(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))+rand_str+'.h5')\n",
    "except OSError:\n",
    "    print(\"Unable to save weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MlPlots.plot_model_log_loss(history)\n",
    "MlPlots.plot_model_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefficient_reconstruction(model, X, Y):\n",
    "    plt.clf()\n",
    "    fig, axarr = plt.subplots(2, 2)\n",
    "    for coeff_idx in range(4):\n",
    "        if(coeff_idx == 0):\n",
    "            i, j = 0,0\n",
    "        elif(coeff_idx == 1):\n",
    "            i, j = 0,1\n",
    "        elif(coeff_idx == 2):\n",
    "            i, j = 1,0\n",
    "        elif(coeff_idx == 3):\n",
    "            i, j = 1,1\n",
    "        else:\n",
    "            break\n",
    "        MAX = 100000\n",
    "\n",
    "        prediction_raw_sample = model.predict(X)[0:MAX][:,coeff_idx]\n",
    "        Y_raw_sample = Y[0:MAX][:,coeff_idx]\n",
    "        predictions = prediction_raw_sample\n",
    "        \n",
    "        axarr[i,j].plot((predictions), label=\"Predicted\", c=\"red\", linewidth=0.8)\n",
    "        axarr[i,j].plot(Y_raw_sample[:], label=\"Data\", linewidth=0.8)\n",
    "        axarr[i,j].title.set_text(\"Mode \" + str(coeff_idx+1))\n",
    "        axarr[i,j].set_ylim([0,1])\n",
    "        axarr[i,j].set_xlim([0,length])\n",
    "        axarr[i,j].set_xlabel(\"Frame Number (16FPS)\")\n",
    "        axarr[i,j].set_ylabel(\"Coefficient\")\n",
    "        axarr[i,j].axvline(x=start_of_test, ymin=0, ymax=100, linewidth=1, color='k')\n",
    "        axarr[i,j].legend(fontsize=10,bbox_to_anchor=(1, 1),loc='center')\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = 10, 5\n",
    "    plt.tight_layout(pad=3.0, w_pad=5.5, h_pad=1.0)\n",
    "    plt.suptitle(\"Eigemode Reconstruction\")\n",
    "    plt.show()\n",
    "\n",
    "X, Y = MlPlots.switch_test_train(trainX, trainY, testX, testY, PlotType.test)\n",
    "plot_coefficient_reconstruction(model, X[start:start+length], Y[start:start+length])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
